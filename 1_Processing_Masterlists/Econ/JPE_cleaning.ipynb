{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1132f336",
   "metadata": {},
   "source": [
    "# JPE cleaning\n",
    "This notebook walks through how the JPE articles were sorted into categories of articles and non-articles.\n",
    "\n",
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import Ignore\n",
    "from numpy import NaN\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from os import path\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3098b7d7",
   "metadata": {},
   "source": [
    "## Loading Files\n",
    "Please replace file paths with local file paths and comment out unapplicable content eg: datadump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07eec85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters = pd.read_excel(\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\Master lists\\\\JPE_master.xlsx\")\n",
    "pivots = pd.read_excel(\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\pivots\\\\JPE_pivots.xlsx\")\n",
    "scopus = pd.read_excel(\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\Scopus\\\\JPE_SCOPUS.xlsx\")\n",
    "datadump = pd.read_excel(\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_datadump.xlsx\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba115e",
   "metadata": {},
   "source": [
    "## Create File names\n",
    "Again, replace these with local file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30587e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_authors.xlsx\"\n",
    "non_auth=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_Nauthors.xlsx\"\n",
    "saveas=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_processed.xlsx\"\n",
    "reviews=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_reviews.xlsx\"\n",
    "misc=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_misc.xlsx\"\n",
    "conf=\"C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_conf.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd6a34",
   "metadata": {},
   "source": [
    "## Some random checks on the masters list\n",
    "My assumption is that all data without author names must be miscellaneous documents like reports by the committee, forewords, front matters etc.. The goal of this notebook is to check for certain that all the documents without author names are actually miscellaneous documents and then classify them as miscellaneous (MISC). Hence, first we group everything the data by title to see the repetitive general content that can likely be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',masters.shape[0])\n",
    "temp=masters['title'].str.lower().value_counts()\n",
    "pd.DataFrame(temp[temp>1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecf915",
   "metadata": {},
   "source": [
    "Some repetitions are due to multiple comments. Now consider this list in absence of author names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da24974",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=masters[masters['authors'].isna()]['title'].str.lower().value_counts()\n",
    "pd.DataFrame(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c5a8c",
   "metadata": {},
   "source": [
    "## Classifying miscellaneous documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus.rename(columns = {'abstract':'abstract2', 'title':'title2', 'authors':'authors2'}, inplace = True)\n",
    "scopus['pages2']=scopus['pages']\n",
    "masters['pages']=masters['pages'].str.strip()\n",
    "masters.loc[masters.title.str.lower() == \"back matter\", 'pages'] = NaN\n",
    "\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'front matter').ratio(), axis=1)>0.75,\"content_type\"]='MISC'\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'back matter').ratio(), axis=1)>0.75,\"content_type\"]='MISC'\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'volume information').ratio(), axis=1)>0.75,\"content_type\"]='MISC'\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'books recieved').ratio(), axis=1)>0.75,\"content_type\"]='MISC'\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'washington notes').ratio(), axis=1)>0.75,\"content_type\"]='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'(in )?memori(a|u)(m|l)')==True, 'content_type']='MISC'\n",
    "masters.loc[masters.apply(lambda k: SequenceMatcher(None, k['title'].lower(), 'books reccieved').ratio(), axis=1)>0.75,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^journal of political economy(.*)')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^index to volume(.*)')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^new publications')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^(prefatory |\\[)note(|s)(|\\])$')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^(|\\[)questions and answers(\\]|)$')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^(|short )notice(|s)$')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^back cover(.*)')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^introduction(.*)')==True,'content_type']='MISC'\n",
    "masters.loc[masters['title'].str.lower().str.match(r'^combined references(.*)')==True,'content_type']='MISC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2710ff7",
   "metadata": {},
   "source": [
    "## Classifying other content types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for how many articles are still unclassified\n",
    "sum(masters.content_type.isna())\n",
    "#masters.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7617c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters['authors'].str.lower().str.match(r'^review(ed|) by(.*)')==True,'content_type']='Review' #reviews\n",
    "masters.loc[(masters['title'].str.lower().str.match(r'(.*) by (.*)')==True) & (masters.authors.isna()==True),'content_type']='Review2' \n",
    "#possible reviews that don't have author names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*: (|a )comment(|.*)$')==True,'content_type']='Comment'\n",
    "masters[masters['content_type']=='Comment'].shape[0] #comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*(:|\\?) (|a )reply(| to.*)$')==True,'content_type']=\"Reply\"\n",
    "masters[masters['content_type']=='Reply'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*(:|\\?) (|a )rejoinder.*$')==True,'content_type']=\"Rejoinder\"\n",
    "masters[masters['content_type']=='Rejoinder'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*: (|a )discussion$')==True,'content_type']=\"Discussion\"\n",
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'(^|a )discussion(|.*)$')==True,'content_type']=\"Discussion\"\n",
    "masters.loc[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*:.*(|a )discussion(|s)$')==True,'content_type']='Discussion'\n",
    "masters[masters['content_type']=='Discussion'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773126ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters.loc[masters['content_type'].isna(),'content_type']=\"Article\"\n",
    "masters[masters['content_type']=='Article'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7068dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block for testing regex matches\n",
    "#masters[masters['title'].str.lower().str.match(r'^\\washington notes$')==True]\n",
    "#masters[masters.content_type.isna() & masters.title.str.lower().str.match(r'.*(:|\\?) (|a )rejoinder.*$')==True]\n",
    "#masters[masters.content_type=='Discussion'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9eecd6",
   "metadata": {},
   "source": [
    "## Consider the pivots file\n",
    "At times, conference papers are structured differently to normal articles. Hence, it may be necessary to distinguish conference papers from common articles. Separate special issues (S) from normal issues (N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivots.loc[pivots.Jstor_issue_text.str.lower().str.match(r'(.*)(supplement|proceedings|annual meeting|survey)(.*)'),'type']=\"S\"\n",
    "pivots.loc[pivots.type.isna(),'type']='N'\n",
    "pivots.type.value_counts()\n",
    "pivots[pivots.type==\"S\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825792ca",
   "metadata": {},
   "source": [
    "Merge pivots and masters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4858fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(masters, pivots[['issue_url','year','volume','issue','journal','type']], how=\"left\", on=[\"issue_url\", \"issue_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac4952",
   "metadata": {},
   "source": [
    "## Summaries of content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.content_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[result.year>1939].content_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result[(result.year>1939) & (result.year<2011)].content_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e72776",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(saveas, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fa495",
   "metadata": {},
   "source": [
    "## This section aims to match up Scopus records and Jstor articles\n",
    "If an article's affiliations, citations or abstracts are recorded on Scopus. matching up the Scopus data is useful for comparing the textual accuracy of OCR parsers. I use volume, issue, year and page numbers which are common to both the scopus data and the Jstor metadata to match articles. \n",
    "\n",
    "Then I use a sequence comparison between the journal titles of the matched articles to decide if the scopus data has been matched correctly. If the match ratio is below 70%, the title is investigated and if wrong, the scopus data for that matched article is either corrected or discarded. \n",
    "\n",
    "The next section reads in the processed data previously saved. Please make sure the path in the variable 'cleaned' matches the file path on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbd2425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned=pd.read_excel('C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\processed\\\\JPE_processed.xlsx')\n",
    "cleaned['volume']=cleaned['volume'].astype(str)\n",
    "scopus['pages']=scopus['pages'].str.strip()\n",
    "#print(scopus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aeb772",
   "metadata": {},
   "source": [
    "This is the number of entries on Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27bea139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965\n"
     ]
    }
   ],
   "source": [
    "#Note that we only have data up to 2016 in the masterlists because of the moving wall on JSTOR\n",
    "print(sum(scopus['year']<2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f5dfc",
   "metadata": {},
   "source": [
    "Merge on year, issue, volume and pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b576b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged=pd.merge(cleaned, scopus, on=['year', 'issue','volume','pages'], how='left')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0595b",
   "metadata": {},
   "source": [
    "Check how many of the scopus entries matched. Good news! Only 9 did not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8fd5cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Merged['title_y'].isna()==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de045720",
   "metadata": {},
   "source": [
    "Consider the titles that have a less than 70% match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fedbc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "0.25757575757575757\n",
      "0.18181818181818182\n",
      "https://www.jstor.org/stable/26549907\n",
      "vol: 124\n",
      "issue: 5\n",
      "pages: 1466-1514\n",
      "jstor: Thomas Jefferson on the “Public Good” Nature of Knowledge\n",
      "scopus: Downward nominal wage rigidity, currency pegs, and involuntary unemployment\n",
      "jstor: Marcos Dal Bianco\n",
      "scopus: Schmitt-Grohé, S.--a--\n",
      "Uribe, M.--b-- \n",
      "scopus index: Int64Index([1014], dtype='int64')\n",
      "20\n",
      "\n",
      "2016\n",
      "0.2857142857142857\n",
      "0.23684210526315788\n",
      "https://www.jstor.org/stable/26549896\n",
      "vol: 124\n",
      "issue: 4\n",
      "pages: 1187-1234\n",
      "jstor: “Market for Lemons” Applied to Social Groups\n",
      "scopus: Intermittency and the value of renewable energy\n",
      "jstor: Joshua S. Goodman\n",
      "scopus: Gowrisankaran, G.--a--\n",
      "Reynolds, S.S.--b--\n",
      "Samano, M.--c-- \n",
      "scopus index: Int64Index([1021], dtype='int64')\n",
      "30\n",
      "\n",
      "2016\n",
      "0.24390243902439024\n",
      "0.17391304347826086\n",
      "https://www.jstor.org/stable/26549885\n",
      "vol: 124\n",
      "issue: 3\n",
      "pages: 826-878\n",
      "jstor: The Gambler’s Fallacy in Existentialist Tragicomedy\n",
      "scopus: Capabilities, wealth, and trade\n",
      "jstor: James Marrone\n",
      "scopus: Sutton, J.--a--\n",
      "Trefler, D.--b-- \n",
      "scopus index: Int64Index([1026], dtype='int64')\n",
      "39\n",
      "\n",
      "2016\n",
      "0.3356643356643357\n",
      "0.07142857142857142\n",
      "https://www.jstor.org/stable/26549875\n",
      "vol: 124\n",
      "issue: 2\n",
      "pages: 579-620\n",
      "jstor: On the Nature of Transition Probabilities and Ergodic Sets in Markov Processes\n",
      "scopus: Explaining cross-country productivity differences in retail trade\n",
      "jstor: David Novgorodsky\n",
      "scopus: Lagakos, D.\n",
      "scopus index: Int64Index([1032], dtype='int64')\n",
      "48\n",
      "\n",
      "2007\n",
      "0.6433566433566433\n",
      "0.5128205128205128\n",
      "https://www.jstor.org/stable/10.1086/523713\n",
      "vol: 115\n",
      "issue: 4\n",
      "pages: 704-705\n",
      "jstor: Erratum: “The Accident Externality from Driving”\n",
      "scopus: Erratum: The accident externality from driving (Journal of Political Economy (2006) 14 (31-55))\n",
      "jstor: Aaron S. Edlin and Pinar Karaca‐Mandic\n",
      "scopus: Edlin, A.S.--a--\n",
      "Karaca-Mandic, P.--b-- \n",
      "scopus index: Int64Index([633], dtype='int64')\n",
      "470\n",
      "\n",
      "1982\n",
      "0.6101694915254238\n",
      "0.3829787234042553\n",
      "https://www.jstor.org/stable/1837132\n",
      "vol: 90\n",
      "issue: 5\n",
      "pages: 1035-1053\n",
      "jstor: Wasteful Commuting\n",
      "scopus: Wasteful commuting ( monocentric models).\n",
      "jstor: Bruce W. Hamilton and Ailsa Röell\n",
      "scopus: Hamilton, B.W.\n",
      "scopus index: Int64Index([145], dtype='int64')\n",
      "2259\n",
      "\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for m in Merged.index:\n",
    "    \n",
    "    if(pd.isna(Merged.iloc[m]['title_y'])==False):\n",
    "        ratio=SequenceMatcher(None, Merged.iloc[m]['title_x'].lower(), Merged.iloc[m]['title_y'].lower()).ratio()\n",
    "\n",
    "        if((ratio<0.7) & (Merged.iloc[m]['content_type']!='MISC')):\n",
    "            print(Merged.iloc[m]['year'])\n",
    "            print(ratio)\n",
    "            count+=1\n",
    "            A_ratio=SequenceMatcher(None, Merged.iloc[m]['authors_x'].lower(), Merged.iloc[m]['authors_y'].lower()).ratio()\n",
    "            print(A_ratio)\n",
    "            print(Merged.iloc[m]['stable_url'])\n",
    "            print('vol: '+str(Merged.iloc[m]['volume']))\n",
    "            print('issue: '+str(Merged.iloc[m]['issue']))\n",
    "            print('pages: '+Merged.iloc[m]['pages'])\n",
    "            print('jstor: '+Merged.iloc[m]['title_x'])\n",
    "            print('scopus: '+Merged.iloc[m]['title_y'])\n",
    "            print('jstor: '+Merged.iloc[m]['authors_x'])\n",
    "            print('scopus: '+Merged.iloc[m]['authors_y'])\n",
    "            print('scopus index: '+str(scopus[scopus['title']==Merged.iloc[m]['title_y']].index))\n",
    "            print(m)\n",
    "            print()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687ee1a",
   "metadata": {},
   "source": [
    "Manually correct some errors in both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36afac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.at[20, 'pages']=float('nan')\n",
    "cleaned.at[30, 'pages']=float('nan')\n",
    "cleaned.at[39, 'pages']=float('nan')\n",
    "cleaned.at[48, 'pages']=float('nan')\n",
    "scopus.at[633, 'title']='Erratum: The accident externality from driving'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b6f9c",
   "metadata": {},
   "source": [
    "Re-merge the scopus data and the cleaned masterlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05b41fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged=pd.merge(cleaned, scopus, on=['year', 'issue','volume','pages'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f4e6f",
   "metadata": {},
   "source": [
    "Check for whether there is an issue in document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5db73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stable_url</th>\n",
       "      <th>authors_x</th>\n",
       "      <th>title_x</th>\n",
       "      <th>abstract_x</th>\n",
       "      <th>content_type</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>pages</th>\n",
       "      <th>year</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>journal_x</th>\n",
       "      <th>type</th>\n",
       "      <th>authors_y</th>\n",
       "      <th>title_y</th>\n",
       "      <th>journal_y</th>\n",
       "      <th>DOI</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>abstract_y</th>\n",
       "      <th>citations</th>\n",
       "      <th>document type</th>\n",
       "      <th>index keywords</th>\n",
       "      <th>author keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [stable_url, authors_x, title_x, abstract_x, content_type, issue_url, pages, year, volume, issue, journal_x, type, authors_y, title_y, journal_y, DOI, affiliations, abstract_y, citations, document type, index keywords, author keywords]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Merged[Merged['document type'].str.len()>100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d0a02",
   "metadata": {},
   "source": [
    "## Merge datadump.xlsx\n",
    "\n",
    "Datadump.xlsx contains reference metadata scraped from JSTOR during sessions running Stage_2_scraper.py. This section merges both the scopus and cleaned data with the references from datadumps. Then this is saved as an excel file. replace path as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5ba7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged=pd.merge(Merged,datadump[['stable_url', 'footnotes','raw','references']], on=['stable_url'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceef2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.rename(columns = {'authors_x':'Jstor_authors', 'title_x':'Jstor_title', 'abstract_x':'Jstor_abstract', 'journal_x':'Jstor_journal', 'authors_y':'scopus_authors','title_y':'scopus_title', 'abstract_y':'scopus_abstract', 'journal_y':'scopus_journal' }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2a437",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2d5e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.to_excel('C:\\\\Users\\\\sjwu1\\\\Journal_Data\\\\datadumps\\\\JPE_M_sco_du.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d190a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09f4ffd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8291c91e",
   "metadata": {},
   "source": [
    "# Merged dataset field description\n",
    "\n",
    "This is a description of fields in the Merged dataset that combines JPE masterlist, pivot list, Scopus data pre-2016. The Merged dataset is stored in JPE_M_sco_du.xlsx.\n",
    "\n",
    "    'stable_url' : JSTOR url for article \n",
    "    'Jstor_authors' : Author names recorded by JSTOR\n",
    "    'Jstor_title' : Title of article recorded by JSTOR\n",
    "    'Jstor_abstract' : abstract recorded by JSTOR nb: this is blank at the moment\n",
    "    'content_type' : Article type determined during cleaning. Includes MISC for miscellaneous, Reviews, Note, Comment, Rejoinder and Article categorizations\n",
    "    'issue_url' : url of issue article belongs to on JSTOR\n",
    "    'pages' : pages as recorded by JSTOR\n",
    "    'year' : Year of publication recorded by JSTOR\n",
    "    'volume' : Volume of article recorded by JSTOR\n",
    "    'issue' : issue of article recorded by JSTOR\n",
    "    'Jstor_journal' : journal name JSTOR\n",
    "    'type' : Type of issue determined during cleaning. S for special issue. N for normal issue\n",
    "    'scopus_authors' : Author names recorded by Scopus\n",
    "    'scopus_title' : Title recorded by Scopus\n",
    "    'scopus_journal' : Journal name recorded by Scopus\n",
    "    'DOI' : DOI recorded by scopus\n",
    "    'affiliations' : affiliations of authors as recorded by scopus\n",
    "    'scopus_abstract' : abstract of article recorded by scopus\n",
    "    'citations' : citations of article recorded by scopus\n",
    "    'document type' : Article type recorded by scopus, may differ from that in cleaning\n",
    "    'index keywords' : from scopus\n",
    "    'author keywords' : from scopus\n",
    "    'footnotes' : footnotes scraped from metadata panel.\n",
    "    'raw' : raw text data scraped from JSTOR metadata panel.\n",
    "    'references' : citations scraped from JSTOR metadata panel during data collection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08f181",
   "metadata": {},
   "source": [
    "### Plots of counts\n",
    "Exploratory analysis of available data in scopus and datadumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "dta=Merged[(Merged['content_type']=='Article') & (Merged['year']>=1940)]['year'].value_counts()\n",
    "plt.bar(dta.index,dta, label='Articles', alpha=0.4)\n",
    "dta2=Merged[Merged['affiliations'].isnull()==False]['year'].value_counts()\n",
    "plt.bar(dta2.index, dta2, label='Scopus coverage', alpha=0.4)\n",
    "plt.title('Barchart of JPE Scopus coverage for affiliations overlaying counts of articles in JPE for each year between 1940 and 2016 (inclusive)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93321761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebe450",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "dta=Merged[(Merged['content_type']=='Article') & (Merged['year']>=1940)]['year'].value_counts()\n",
    "dta.index\n",
    "plt.bar(dta.index, dta, alpha=0.4, label='Articles')\n",
    "dta3=Merged[Merged['citations'].isnull()==False]['year'].value_counts()\n",
    "plt.bar(dta3.index, dta3, alpha=0.4, label='Scopus coverage')\n",
    "dta4=Merged[Merged['references'].isnull()==False]['year'].value_counts()\n",
    "plt.bar(dta4.index, dta4, alpha=0.4, label='Datadump coverage')\n",
    "plt.title('Barchart of JPE Scopus coverage for references and references scraped from JSTOR overlaying counts of articles in JPE for each year between 1940 and 2016 (inclusive)')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
