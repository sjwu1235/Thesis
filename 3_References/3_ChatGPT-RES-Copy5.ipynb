{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dfbcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt         # displaying output images\n",
    "import cv2 \n",
    "import openai\n",
    "import json\n",
    "import regex\n",
    "import tiktoken\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "734146f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Refs Danae/Thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c4546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429a831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    #gpt-3.5-turbo-16k\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    r_out = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        request_timeout=1000\n",
    "    )\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa75b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Refs Danae/Thesis/Data\"\n",
    "temp=base_path+'/PDFs/RES/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ffabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged=pd.read_excel(base_path+'/Combined/RES_M_sco_du.xlsx')\n",
    "Merged.loc[Merged['journal']==\"The Review of Economic Studies\",'journal']='RES'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2d4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged[\"ID\"]=Merged[\"URL\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d310c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=\"/Users/sijiawu/Work/Refs Danae/Thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e959c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1=pt+\"/Data\\RES_refs_output_2011_2020.json\"\n",
    "res_2=pt+\"/Data\\RES_refs_output_2001_2010.json\"\n",
    "res_3=pt+\"/Data\\RES_refs_output_1991_2000.json\"\n",
    "res_4=pt+\"/Data\\RES_refs_output_1981_1990.json\"\n",
    "res_5=pt+\"/Data\\RES_refs_output_1971_1980.json\"\n",
    "res_6=pt+\"/Data\\RES_refs_output_1961_1970.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec84aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}\n",
    "res=[\n",
    "#     res_1,\n",
    "      res_2,\n",
    "#       res_3,\n",
    "#       res_4,\n",
    "#       res_5,\n",
    "#       res_6\n",
    "     ]\n",
    "for file in res:\n",
    "    with open(file) as f:\n",
    "        temp_data = json.load(f)\n",
    "        data=data|temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada755f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f568a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    #gpt-3.5-turbo-16k\n",
    "    #gpt-3.5-turbo-0613\n",
    "#   \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54918e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "b2b836bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.833333333333336"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())*300/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "459913dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "948d0688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "d21ce207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "cd9de53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ec0e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 to parse\n",
      "current time:- 2023-11-03 02:07:47.043281\n",
      "1772 too long. Using big context model.\n",
      "150 4626196 completed\n",
      "86.47739100456238\n",
      "1772\n",
      "current time:- 2023-11-03 02:09:13.526538\n",
      "909 standard\n",
      "151 4626197 completed\n",
      "37.98446297645569\n",
      "909\n",
      "pdf not available. download 4626198\n",
      "current time:- 2023-11-03 02:09:51.513398\n",
      "1743 too long. Using big context model.\n",
      "153 4626171 completed\n",
      "88.37542605400085\n",
      "1743\n",
      "current time:- 2023-11-03 02:11:19.921118\n",
      "2033 too long. Using big context model.\n",
      "154 4626172 completed\n",
      "102.21043992042542\n",
      "2033\n",
      "current time:- 2023-11-03 02:13:02.127793\n",
      "2746 too long. Using big context model.\n",
      "155 4626173 completed\n",
      "146.44984912872314\n",
      "2746\n",
      "current time:- 2023-11-03 02:15:28.591049\n",
      "2801 too long. Using big context model.\n",
      "156 4626174 completed\n",
      "148.6756353378296\n",
      "2801\n",
      "current time:- 2023-11-03 02:17:57.272513\n",
      "1668 too long. Using big context model.\n",
      "157 4626175 completed\n",
      "108.73563599586487\n",
      "1668\n",
      "current time:- 2023-11-03 02:19:46.017951\n",
      "2651 too long. Using big context model.\n",
      "158 4626176 completed\n",
      "158.24930787086487\n",
      "2651\n",
      "current time:- 2023-11-03 02:22:24.276676\n",
      "1176 too long. Using big context model.\n",
      "159 4626177 completed\n",
      "63.58327889442444\n",
      "1176\n",
      "current time:- 2023-11-03 02:23:27.865581\n",
      "2933 too long. Using big context model.\n",
      "160 4626178 completed\n",
      "161.93738293647766\n",
      "2933\n",
      "current time:- 2023-11-03 02:26:09.815987\n",
      "2715 too long. Using big context model.\n",
      "161 4626179 completed\n",
      "162.92832827568054\n",
      "2715\n",
      "current time:- 2023-11-03 02:28:52.749064\n",
      "1857 too long. Using big context model.\n",
      "162 4626180 completed\n",
      "96.90185379981995\n",
      "1857\n",
      "current time:- 2023-11-03 02:30:29.644578\n",
      "972 standard\n",
      "163 4626181 completed\n",
      "52.73605990409851\n",
      "972\n",
      "current time:- 2023-11-03 02:31:22.392681\n",
      "2526 too long. Using big context model.\n",
      "164 4626182 completed\n",
      "152.736643075943\n",
      "2526\n",
      "current time:- 2023-11-03 02:33:55.143443\n",
      "2012 too long. Using big context model.\n",
      "165 4626183 completed\n",
      "114.64113283157349\n",
      "2012\n",
      "current time:- 2023-11-03 02:35:49.788447\n",
      "1505 too long. Using big context model.\n",
      "166 4626156 completed\n",
      "80.92575216293335\n",
      "1505\n",
      "current time:- 2023-11-03 02:37:10.725639\n",
      "1457 too long. Using big context model.\n",
      "167 4626157 completed\n",
      "73.8958489894867\n",
      "1457\n",
      "current time:- 2023-11-03 02:38:24.620741\n",
      "1078 standard\n",
      "168 4626158 completed\n",
      "56.28575611114502\n",
      "1078\n",
      "current time:- 2023-11-03 02:39:20.919026\n",
      "1720 too long. Using big context model.\n",
      "169 4626159 completed\n",
      "85.62170505523682\n",
      "1720\n",
      "current time:- 2023-11-03 02:40:46.554173\n",
      "2431 too long. Using big context model.\n",
      "170 4626160 completed\n",
      "130.77441811561584\n",
      "2431\n",
      "current time:- 2023-11-03 02:42:57.344217\n",
      "2759 too long. Using big context model.\n",
      "171 4626161 completed\n",
      "155.79209804534912\n",
      "2759\n",
      "current time:- 2023-11-03 02:45:33.148063\n",
      "2018 too long. Using big context model.\n",
      "172 4626162 completed\n",
      "106.70168590545654\n",
      "2018\n",
      "current time:- 2023-11-03 02:47:19.862163\n",
      "3058 too long. Using big context model.\n",
      "173 4626163 completed\n",
      "147.38585019111633\n",
      "3058\n",
      "current time:- 2023-11-03 02:49:47.265615\n",
      "3097 too long. Using big context model.\n",
      "174 4626164 completed\n",
      "174.07210421562195\n",
      "3097\n",
      "current time:- 2023-11-03 02:52:41.349137\n",
      "1677 too long. Using big context model.\n",
      "175 4626165 completed\n",
      "133.37668108940125\n",
      "1677\n",
      "current time:- 2023-11-03 02:54:54.735664\n",
      "4626166 this has an abnormally long reference list at 4052, process separately\n",
      "current time:- 2023-11-03 02:54:54.739243\n",
      "2684 too long. Using big context model.\n",
      "177 4626167 completed\n",
      "163.98887491226196\n",
      "2684\n",
      "current time:- 2023-11-03 02:57:38.760930\n",
      "2559 too long. Using big context model.\n",
      "178 4626144 completed\n",
      "131.34029412269592\n",
      "2559\n",
      "current time:- 2023-11-03 02:59:50.110572\n",
      "2646 too long. Using big context model.\n",
      "179 4626145 completed\n",
      "133.24981498718262\n",
      "2646\n",
      "current time:- 2023-11-03 03:02:03.374922\n",
      "2176 too long. Using big context model.\n",
      "180 4626146 completed\n",
      "136.55833411216736\n",
      "2176\n",
      "current time:- 2023-11-03 03:04:19.943751\n",
      "1125 too long. Using big context model.\n",
      "181 4626147 completed\n",
      "65.73394989967346\n",
      "1125\n",
      "current time:- 2023-11-03 03:05:25.690002\n",
      "1505 too long. Using big context model.\n",
      "182 4626148 completed\n",
      "95.34962677955627\n",
      "1505\n",
      "current time:- 2023-11-03 03:07:01.055655\n",
      "2061 too long. Using big context model.\n",
      "183 4626149 completed\n",
      "120.71533417701721\n",
      "2061\n",
      "current time:- 2023-11-03 03:09:01.783519\n",
      "1769 too long. Using big context model.\n",
      "184 4626150 completed\n",
      "100.85226607322693\n",
      "1769\n",
      "current time:- 2023-11-03 03:10:42.651098\n",
      "1317 too long. Using big context model.\n",
      "185 4626151 completed\n",
      "71.726233959198\n",
      "1317\n",
      "current time:- 2023-11-03 03:11:54.378923\n",
      "1534 too long. Using big context model.\n",
      "186 4626152 completed\n",
      "102.6595299243927\n",
      "1534\n",
      "current time:- 2023-11-03 03:13:37.057273\n",
      "4626153 this has an abnormally long reference list at 3634, process separately\n",
      "current time:- 2023-11-03 03:13:37.061603\n",
      "1454 too long. Using big context model.\n",
      "188 4123235 completed\n",
      "73.35173416137695\n",
      "1454\n",
      "current time:- 2023-11-03 03:14:50.422937\n",
      "2187 too long. Using big context model.\n",
      "189 4123236 completed\n",
      "163.6138551235199\n",
      "2187\n",
      "current time:- 2023-11-03 03:17:34.051376\n",
      "1251 too long. Using big context model.\n",
      "190 4123237 completed\n",
      "99.41349196434021\n",
      "1251\n",
      "current time:- 2023-11-03 03:19:13.490907\n",
      "868 standard\n",
      "191 4123238 completed\n",
      "44.51541996002197\n",
      "868\n",
      "current time:- 2023-11-03 03:19:58.003120\n",
      "2183 too long. Using big context model.\n",
      "192 4123239 completed\n",
      "121.48674511909485\n",
      "2183\n",
      "current time:- 2023-11-03 03:21:59.517210\n",
      "1127 too long. Using big context model.\n",
      "193 4123240 completed\n",
      "64.25715398788452\n",
      "1127\n",
      "current time:- 2023-11-03 03:23:03.770690\n",
      "1518 too long. Using big context model.\n",
      "194 4123241 completed\n",
      "98.34753799438477\n",
      "1518\n",
      "current time:- 2023-11-03 03:24:42.133213\n",
      "2276 too long. Using big context model.\n",
      "195 4123242 completed\n",
      "149.30775594711304\n",
      "2276\n",
      "current time:- 2023-11-03 03:27:11.461697\n",
      "1301 too long. Using big context model.\n",
      "196 4123243 completed\n",
      "65.1377501487732\n",
      "1301\n",
      "current time:- 2023-11-03 03:28:16.594921\n",
      "2629 too long. Using big context model.\n",
      "197 4123244 completed\n",
      "5.394773006439209\n",
      "2629\n",
      "current time:- 2023-11-03 03:28:22.000079\n",
      "3427 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "600.3710248470306\n",
      "3427\n",
      "199 4123246 completed\n",
      "200 4123250 completed\n",
      "201 4123251 completed\n",
      "202 4123252 completed\n",
      "203 4123253 completed\n",
      "204 4123254 completed\n",
      "205 4123255 completed\n",
      "206 4123256 completed\n",
      "207 4123257 completed\n",
      "208 4123258 completed\n",
      "209 4123259 completed\n",
      "210 4123260 completed\n",
      "211 4123261 completed\n",
      "212 20185020 completed\n",
      "current time:- 2023-11-03 03:38:22.393364\n",
      "20185021 this has an abnormally long reference list at 3601, process separately\n",
      "214 20185022 completed\n",
      "current time:- 2023-11-03 03:38:22.400288\n",
      "20185023 this has an abnormally long reference list at 3644, process separately\n",
      "216 20185024 completed\n",
      "217 20185025 completed\n",
      "218 20185026 completed\n",
      "219 20185027 completed\n",
      "220 20185028 completed\n",
      "221 20185029 completed\n",
      "222 20185030 completed\n",
      "pdf not available. download 20185031\n",
      "224 3700641 completed\n",
      "225 3700642 completed\n",
      "226 3700643 completed\n",
      "227 3700644 completed\n",
      "228 3700645 completed\n",
      "229 3700646 completed\n",
      "current time:- 2023-11-03 03:38:22.407522\n",
      "3700647 this has an abnormally long reference list at 4144, process separately\n",
      "231 3700648 completed\n",
      "232 3700649 completed\n",
      "233 3700650 completed\n",
      "234 3700615 completed\n",
      "235 3700616 completed\n",
      "236 3700617 completed\n",
      "current time:- 2023-11-03 03:38:22.413759\n",
      "3700618 this has an abnormally long reference list at 4836, process separately\n",
      "238 3700619 completed\n",
      "239 3700620 completed\n",
      "240 3700621 completed\n",
      "241 3700622 completed\n",
      "242 3700623 completed\n",
      "3700624 has no references, check it\n",
      "2006\n",
      "244 3700696 completed\n",
      "245 3700697 completed\n",
      "246 3700698 completed\n",
      "247 3700699 completed\n",
      "248 3700700 completed\n",
      "249 3700701 completed\n",
      "250 3700702 completed\n",
      "251 3700703 completed\n",
      "252 3700704 completed\n",
      "253 3700705 completed\n",
      "254 3700667 completed\n",
      "255 3700668 completed\n",
      "256 3700669 completed\n",
      "257 3700670 completed\n",
      "258 3700671 completed\n",
      "259 3700672 completed\n",
      "current time:- 2023-11-03 03:38:22.418914\n",
      "3700673 this has an abnormally long reference list at 3736, process separately\n",
      "261 3700674 completed\n",
      "current time:- 2023-11-03 03:38:22.422680\n",
      "3700675 this has an abnormally long reference list at 3683, process separately\n",
      "263 3700676 completed\n",
      "264 3700677 completed\n",
      "265 3700678 completed\n",
      "current time:- 2023-11-03 03:38:22.426446\n",
      "3700653 this has an abnormally long reference list at 3719, process separately\n",
      "267 3700654 completed\n",
      "268 3700655 completed\n",
      "269 3700656 completed\n",
      "270 3700657 completed\n",
      "271 3700658 completed\n",
      "272 3700659 completed\n",
      "273 3700660 completed\n",
      "current time:- 2023-11-03 03:38:22.431455\n",
      "3700661 this has an abnormally long reference list at 4769, process separately\n",
      "275 3700662 completed\n",
      "276 3700663 completed\n",
      "277 3700664 completed\n",
      "current time:- 2023-11-03 03:38:22.433677\n",
      "2245 too long. Using big context model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 3700681 completed\n",
      "125.45481514930725\n",
      "2245\n",
      "current time:- 2023-11-03 03:40:27.896059\n",
      "940 standard\n",
      "279 3700682 completed\n",
      "51.86421298980713\n",
      "940\n",
      "current time:- 2023-11-03 03:41:19.767361\n",
      "1022 standard\n",
      "280 3700683 completed\n",
      "61.16850686073303\n",
      "1022\n",
      "current time:- 2023-11-03 03:42:20.942916\n",
      "1698 too long. Using big context model.\n",
      "281 3700684 completed\n",
      "99.12345099449158\n",
      "1698\n",
      "current time:- 2023-11-03 03:44:00.083949\n",
      "2619 too long. Using big context model.\n",
      "282 3700685 completed\n",
      "164.10293197631836\n",
      "2619\n",
      "current time:- 2023-11-03 03:46:44.188146\n",
      "1290 too long. Using big context model.\n",
      "283 3700686 completed\n",
      "75.90097880363464\n",
      "1290\n",
      "current time:- 2023-11-03 03:48:00.094982\n",
      "1223 too long. Using big context model.\n",
      "284 3700687 completed\n",
      "83.7033998966217\n",
      "1223\n",
      "current time:- 2023-11-03 03:49:23.800755\n",
      "3396 too long. Using big context model.\n",
      "285 3700688 completed\n",
      "217.20911812782288\n",
      "3396\n",
      "current time:- 2023-11-03 03:53:01.022130\n",
      "3700689 this has an abnormally long reference list at 3579, process separately\n",
      "current time:- 2023-11-03 03:53:01.026996\n",
      "1439 too long. Using big context model.\n",
      "287 3700690 completed\n",
      "91.41594076156616\n",
      "1439\n",
      "current time:- 2023-11-03 03:54:32.448493\n",
      "1527 too long. Using big context model.\n",
      "288 3700691 completed\n",
      "88.70748019218445\n",
      "1527\n",
      "current time:- 2023-11-03 03:56:01.166890\n",
      "2183 too long. Using big context model.\n",
      "289 3700692 completed\n",
      "138.4297070503235\n",
      "2183\n",
      "current time:- 2023-11-03 03:58:19.601718\n",
      "1675 too long. Using big context model.\n",
      "290 3700723 completed\n",
      "103.46531081199646\n",
      "1675\n",
      "current time:- 2023-11-03 04:00:03.071706\n",
      "2140 too long. Using big context model.\n",
      "291 3700724 completed\n",
      "117.20730686187744\n",
      "2140\n",
      "current time:- 2023-11-03 04:02:00.289012\n",
      "983 standard\n",
      "292 3700725 completed\n",
      "61.43035864830017\n",
      "983\n",
      "current time:- 2023-11-03 04:03:01.726948\n",
      "3230 too long. Using big context model.\n",
      "293 3700726 completed\n",
      "230.58066701889038\n",
      "3230\n",
      "current time:- 2023-11-03 04:06:52.322419\n",
      "1676 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "7145.1759560108185\n",
      "1676\n",
      "current time:- 2023-11-03 06:05:57.508749\n",
      "1219 too long. Using big context model.\n",
      "295 3700728 completed\n",
      "66.32004594802856\n",
      "1219\n",
      "current time:- 2023-11-03 06:07:03.832456\n",
      "1418 too long. Using big context model.\n",
      "296 3700729 completed\n",
      "80.0562961101532\n",
      "1418\n",
      "current time:- 2023-11-03 06:08:23.894788\n",
      "1132 too long. Using big context model.\n",
      "297 3700730 completed\n",
      "68.49229907989502\n",
      "1132\n",
      "current time:- 2023-11-03 06:09:32.390938\n",
      "1358 too long. Using big context model.\n",
      "298 3700731 completed\n",
      "112.95273923873901\n",
      "1358\n",
      "current time:- 2023-11-03 06:11:25.349202\n",
      "1296 too long. Using big context model.\n",
      "299 3700732 completed\n",
      "118.30042600631714\n",
      "1296\n",
      "current time:- 2023-11-03 06:13:23.656849\n",
      "1504 too long. Using big context model.\n",
      "300 3700733 completed\n",
      "109.72832703590393\n",
      "1504\n",
      "current time:- 2023-11-03 06:15:13.387412\n",
      "1625 too long. Using big context model.\n",
      "301 3700734 completed\n",
      "94.7038037776947\n",
      "1625\n",
      "current time:- 2023-11-03 06:16:48.100607\n",
      "1869 too long. Using big context model.\n",
      "302 3700737 completed\n",
      "101.9882640838623\n",
      "1869\n",
      "current time:- 2023-11-03 06:18:30.095419\n",
      "1163 too long. Using big context model.\n",
      "303 3700738 completed\n",
      "53.806071043014526\n",
      "1163\n",
      "current time:- 2023-11-03 06:19:23.911290\n",
      "1641 too long. Using big context model.\n",
      "304 3700739 completed\n",
      "87.57309293746948\n",
      "1641\n",
      "current time:- 2023-11-03 06:20:51.490963\n",
      "1728 too long. Using big context model.\n",
      "305 3700740 completed\n",
      "92.95891118049622\n",
      "1728\n",
      "current time:- 2023-11-03 06:22:24.455713\n",
      "1842 too long. Using big context model.\n",
      "306 3700741 completed\n",
      "88.20146822929382\n",
      "1842\n",
      "current time:- 2023-11-03 06:23:52.666025\n",
      "2758 too long. Using big context model.\n",
      "307 3700742 completed\n",
      "164.70006585121155\n",
      "2758\n",
      "current time:- 2023-11-03 06:26:37.369825\n",
      "1635 too long. Using big context model.\n",
      "308 3700743 completed\n",
      "80.27234601974487\n",
      "1635\n",
      "current time:- 2023-11-03 06:27:57.651330\n",
      "1780 too long. Using big context model.\n",
      "309 3700744 completed\n",
      "99.66574907302856\n",
      "1780\n",
      "current time:- 2023-11-03 06:29:37.321033\n",
      "836 standard\n",
      "310 3700745 completed\n",
      "36.92505192756653\n",
      "836\n",
      "current time:- 2023-11-03 06:30:14.253281\n",
      "2055 too long. Using big context model.\n",
      "311 3700746 completed\n",
      "146.1219620704651\n",
      "2055\n",
      "current time:- 2023-11-03 06:32:40.377437\n",
      "757 standard\n",
      "312 3700747 completed\n",
      "35.32115721702576\n",
      "757\n",
      "current time:- 2023-11-03 06:33:15.707238\n",
      "1547 too long. Using big context model.\n",
      "313 3700748 completed\n",
      "83.16698002815247\n",
      "1547\n",
      "current time:- 2023-11-03 06:34:38.881513\n",
      "2673 too long. Using big context model.\n",
      "314 3700627 completed\n",
      "167.70812273025513\n",
      "2673\n",
      "current time:- 2023-11-03 06:37:26.594549\n",
      "2024 too long. Using big context model.\n",
      "315 3700628 completed\n",
      "136.49165415763855\n",
      "2024\n",
      "current time:- 2023-11-03 06:39:43.091459\n",
      "1337 too long. Using big context model.\n",
      "316 3700629 completed\n",
      "79.92825078964233\n",
      "1337\n",
      "current time:- 2023-11-03 06:41:03.022069\n",
      "1393 too long. Using big context model.\n",
      "317 3700630 completed\n",
      "76.7222409248352\n",
      "1393\n",
      "current time:- 2023-11-03 06:42:19.748153\n",
      "1337 too long. Using big context model.\n",
      "318 3700631 completed\n",
      "59.28680896759033\n",
      "1337\n",
      "current time:- 2023-11-03 06:43:19.041295\n",
      "1438 too long. Using big context model.\n",
      "319 3700632 completed\n",
      "82.8358702659607\n",
      "1438\n",
      "current time:- 2023-11-03 06:44:41.883875\n",
      "1801 too long. Using big context model.\n",
      "320 3700633 completed\n",
      "85.56176114082336\n",
      "1801\n",
      "current time:- 2023-11-03 06:46:07.454676\n",
      "2176 too long. Using big context model.\n",
      "321 3700634 completed\n",
      "121.38060021400452\n",
      "2176\n",
      "current time:- 2023-11-03 06:48:08.840527\n",
      "1725 too long. Using big context model.\n",
      "322 3700635 completed\n",
      "108.56999397277832\n",
      "1725\n",
      "current time:- 2023-11-03 06:49:57.421545\n",
      "1600 too long. Using big context model.\n",
      "323 3700636 completed\n",
      "97.13583207130432\n",
      "1600\n",
      "current time:- 2023-11-03 06:51:34.557670\n",
      "984 standard\n",
      "324 3700637 completed\n",
      "46.182576179504395\n",
      "984\n",
      "current time:- 2023-11-03 06:52:20.747963\n",
      "1424 too long. Using big context model.\n",
      "325 3700638 completed\n",
      "98.24649095535278\n",
      "1424\n",
      "current time:- 2023-11-03 06:53:59.001997\n",
      "1760 too long. Using big context model.\n",
      "326 3700708 completed\n",
      "98.29713320732117\n",
      "1760\n",
      "current time:- 2023-11-03 06:55:37.304660\n",
      "1310 too long. Using big context model.\n",
      "327 3700709 completed\n",
      "71.60195398330688\n",
      "1310\n",
      "current time:- 2023-11-03 06:56:48.911830\n",
      "1351 too long. Using big context model.\n",
      "328 3700710 completed\n",
      "82.97127485275269\n",
      "1351\n",
      "current time:- 2023-11-03 06:58:11.898029\n",
      "1310 too long. Using big context model.\n",
      "329 3700711 completed\n",
      "91.62735223770142\n",
      "1310\n",
      "current time:- 2023-11-03 06:59:43.529517\n",
      "1676 too long. Using big context model.\n",
      "330 3700712 completed\n",
      "89.17063808441162\n",
      "1676\n",
      "current time:- 2023-11-03 07:01:12.705989\n",
      "1146 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "3868.085175037384\n",
      "1146\n",
      "current time:- 2023-11-03 08:05:40.799652\n",
      "855 standard\n",
      "332 3700714 completed\n",
      "43.82978177070618\n",
      "855\n",
      "current time:- 2023-11-03 08:06:24.636965\n",
      "1330 too long. Using big context model.\n",
      "333 3700715 completed\n",
      "82.8098030090332\n",
      "1330\n",
      "current time:- 2023-11-03 08:07:47.452950\n",
      "1834 too long. Using big context model.\n",
      "334 3700716 completed\n",
      "136.4217689037323\n",
      "1834\n",
      "current time:- 2023-11-03 08:10:03.876815\n",
      "1528 too long. Using big context model.\n",
      "335 3700717 completed\n",
      "108.37842082977295\n",
      "1528\n",
      "current time:- 2023-11-03 08:11:52.260914\n",
      "1424 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "2936.0502989292145\n",
      "1424\n",
      "current time:- 2023-11-03 09:00:48.327959\n",
      "1539 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "3586.6677570343018\n",
      "1539\n",
      "current time:- 2023-11-03 10:00:35.010467\n",
      "1000 standard\n",
      "338 3648620 completed\n",
      "59.49715304374695\n",
      "1000\n",
      "current time:- 2023-11-03 10:01:34.509164\n",
      "1318 too long. Using big context model.\n",
      "339 3648621 completed\n",
      "74.0586109161377\n",
      "1318\n",
      "current time:- 2023-11-03 10:02:48.575612\n",
      "1689 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "3117.4875979423523\n",
      "1689\n",
      "current time:- 2023-11-03 10:54:46.079153\n",
      "1709 too long. Using big context model.\n",
      "341 3648623 completed\n",
      "151.54252696037292\n",
      "1709\n",
      "current time:- 2023-11-03 10:57:17.634154\n",
      "1534 too long. Using big context model.\n",
      "342 3648624 completed\n",
      "87.84893083572388\n",
      "1534\n",
      "current time:- 2023-11-03 10:58:45.485057\n",
      "1314 too long. Using big context model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 3648625 completed\n",
      "96.5595211982727\n",
      "1314\n",
      "current time:- 2023-11-03 11:00:22.055547\n",
      "2674 too long. Using big context model.\n",
      "this took too long to respond, complete next round. Moving on!\n",
      "145.46822094917297\n",
      "2674\n",
      "current time:- 2023-11-03 11:02:47.536773\n",
      "2071 too long. Using big context model.\n",
      "345 3648627 completed\n",
      "159.05192494392395\n",
      "2071\n",
      "current time:- 2023-11-03 11:05:26.586018\n",
      "1308 too long. Using big context model.\n",
      "346 3648628 completed\n",
      "93.86228108406067\n",
      "1308\n",
      "current time:- 2023-11-03 11:07:00.457938\n",
      "1206 too long. Using big context model.\n",
      "347 3648629 completed\n",
      "96.74917721748352\n",
      "1206\n",
      "current time:- 2023-11-03 11:08:37.216686\n",
      "1978 too long. Using big context model.\n",
      "348 3648597 completed\n",
      "120.02546095848083\n",
      "1978\n",
      "current time:- 2023-11-03 11:10:37.257074\n",
      "2726 too long. Using big context model.\n",
      "349 3648598 completed\n",
      "194.39528608322144\n",
      "2726\n",
      "350 3648599 completed\n",
      "current time:- 2023-11-03 11:13:51.689381\n",
      "1954 too long. Using big context model.\n",
      "351 3648600 completed\n",
      "167.37993597984314\n",
      "1954\n",
      "current time:- 2023-11-03 11:16:39.057466\n",
      "1695 too long. Using big context model.\n",
      "352 3648601 completed\n",
      "125.9143078327179\n",
      "1695\n",
      "current time:- 2023-11-03 11:18:44.978577\n",
      "1309 too long. Using big context model.\n",
      "353 3648602 completed\n",
      "90.55948615074158\n",
      "1309\n",
      "current time:- 2023-11-03 11:20:15.541511\n",
      "672 standard\n",
      "354 3648603 completed\n",
      "41.47242093086243\n",
      "672\n",
      "current time:- 2023-11-03 11:20:57.024454\n",
      "1803 too long. Using big context model.\n",
      "355 3648604 completed\n",
      "136.51267290115356\n",
      "1803\n",
      "current time:- 2023-11-03 11:23:13.539036\n",
      "1438 too long. Using big context model.\n",
      "356 3648605 completed\n",
      "93.9855089187622\n",
      "1438\n",
      "current time:- 2023-11-03 11:24:47.529981\n",
      "1381 too long. Using big context model.\n",
      "357 3648606 completed\n",
      "102.75446319580078\n",
      "1381\n",
      "current time:- 2023-11-03 11:26:30.300142\n",
      "3648632 this has an abnormally long reference list at 3718, process separately\n",
      "current time:- 2023-11-03 11:26:30.303994\n",
      "718 standard\n",
      "359 3648633 completed\n",
      "40.38560366630554\n",
      "718\n",
      "current time:- 2023-11-03 11:27:10.701879\n",
      "1795 too long. Using big context model.\n",
      "360 3648634 completed\n",
      "129.00214409828186\n",
      "1795\n",
      "current time:- 2023-11-03 11:29:19.714743\n",
      "2876 too long. Using big context model.\n",
      "361 3648635 completed\n",
      "210.51686310768127\n",
      "2876\n",
      "current time:- 2023-11-03 11:32:50.244643\n",
      "1867 too long. Using big context model.\n",
      "362 3648636 completed\n",
      "126.05646896362305\n",
      "1867\n",
      "current time:- 2023-11-03 11:34:56.301970\n",
      "919 standard\n",
      "363 3648637 completed\n",
      "81.81631684303284\n",
      "919\n",
      "current time:- 2023-11-03 11:36:18.135477\n",
      "1774 too long. Using big context model.\n",
      "364 3648638 completed\n",
      "105.41826319694519\n",
      "1774\n",
      "current time:- 2023-11-03 11:38:03.554140\n",
      "1225 too long. Using big context model.\n",
      "365 3648639 completed\n",
      "92.83004999160767\n",
      "1225\n",
      "current time:- 2023-11-03 11:39:36.399120\n",
      "690 standard\n",
      "366 3648640 completed\n",
      "46.03370714187622\n",
      "690\n",
      "current time:- 2023-11-03 11:40:22.441439\n",
      "2216 too long. Using big context model.\n",
      "367 3648641 completed\n",
      "123.30601096153259\n",
      "2216\n",
      "current time:- 2023-11-03 11:42:25.757845\n",
      "1678 too long. Using big context model.\n",
      "368 3648609 completed\n",
      "108.90418291091919\n",
      "1678\n",
      "current time:- 2023-11-03 11:44:14.679226\n",
      "1239 too long. Using big context model.\n",
      "369 3648610 completed\n",
      "70.3139820098877\n",
      "1239\n",
      "current time:- 2023-11-03 11:45:24.993072\n",
      "2553 too long. Using big context model.\n",
      "370 3648611 completed\n",
      "163.41924619674683\n",
      "2553\n",
      "current time:- 2023-11-03 11:48:08.424436\n",
      "1979 too long. Using big context model.\n",
      "371 3648612 completed\n",
      "122.53999590873718\n",
      "1979\n",
      "current time:- 2023-11-03 11:50:10.966911\n",
      "1434 too long. Using big context model.\n",
      "372 3648613 completed\n",
      "86.43432188034058\n",
      "1434\n",
      "current time:- 2023-11-03 11:51:37.405653\n",
      "1155 too long. Using big context model.\n",
      "373 3648614 completed\n",
      "58.07692503929138\n",
      "1155\n",
      "current time:- 2023-11-03 11:52:35.489807\n",
      "1435 too long. Using big context model.\n",
      "374 3648615 completed\n",
      "88.02610397338867\n",
      "1435\n",
      "current time:- 2023-11-03 11:54:03.533614\n",
      "1929 too long. Using big context model.\n",
      "375 1556721 completed\n",
      "115.81400680541992\n",
      "1929\n",
      "current time:- 2023-11-03 11:55:59.351802\n",
      "3009 too long. Using big context model.\n",
      "376 1556722 completed\n",
      "183.7860291004181\n",
      "3009\n",
      "377 1556723 completed\n",
      "378 1556724 completed\n",
      "379 1556725 completed\n",
      "380 1556726 completed\n",
      "381 1556727 completed\n",
      "382 1556728 completed\n",
      "383 1556729 completed\n",
      "384 1556730 completed\n",
      "385 1556708 completed\n",
      "386 1556709 completed\n",
      "387 1556710 completed\n",
      "388 1556711 completed\n",
      "389 1556712 completed\n",
      "390 1556713 completed\n",
      "391 1556714 completed\n",
      "392 1556715 completed\n",
      "393 1556716 completed\n",
      "394 1556717 completed\n",
      "395 1556733 completed\n",
      "current time:- 2023-11-03 11:59:03.147235\n",
      "676 standard\n",
      "396 1556734 completed\n",
      "42.95714807510376\n",
      "676\n",
      "current time:- 2023-11-03 11:59:46.103403\n",
      "1099 standard\n",
      "397 1556735 completed\n",
      "70.65336608886719\n",
      "1099\n",
      "current time:- 2023-11-03 12:00:56.761874\n",
      "1221 too long. Using big context model.\n",
      "398 1556736 completed\n",
      "65.32838988304138\n",
      "1221\n",
      "current time:- 2023-11-03 12:02:02.098906\n",
      "2057 too long. Using big context model.\n",
      "399 1556737 completed\n",
      "124.24250817298889\n",
      "2057\n",
      "400 1556738 completed\n",
      "401 1556739 completed\n",
      "402 1556740 completed\n",
      "403 2695951 completed\n",
      "404 2695952 completed\n",
      "405 2695953 completed\n",
      "406 2695954 completed\n",
      "407 2695955 completed\n",
      "408 2695956 completed\n",
      "409 2695957 completed\n",
      "410 2695958 completed\n",
      "411 2695959 completed\n",
      "412 2695960 completed\n",
      "413 2695961 completed\n",
      "414 2695907 completed\n",
      "415 2695908 completed\n",
      "416 2695909 completed\n",
      "417 2695910 completed\n",
      "418 2695911 completed\n",
      "419 2695912 completed\n",
      "420 2695913 completed\n",
      "421 2695893 completed\n",
      "422 2695894 completed\n",
      "423 2695895 completed\n",
      "424 2695896 completed\n",
      "425 2695897 completed\n",
      "426 2695898 completed\n",
      "427 2695899 completed\n",
      "428 2695900 completed\n",
      "429 2695901 completed\n",
      "430 2695902 completed\n",
      "pdf not available. download 2695903\n",
      "2695928 has no references, check it\n",
      "2001\n",
      "433 2695929 completed\n",
      "434 2695930 completed\n",
      "435 2695931 completed\n",
      "436 2695932 completed\n",
      "437 2695933 completed\n",
      "438 2695934 completed\n",
      "439 2695935 completed\n",
      "440 2695936 completed\n",
      "441 2695916 completed\n",
      "442 2695917 completed\n",
      "443 2695918 completed\n",
      "444 2695919 completed\n",
      "445 2695920 completed\n",
      "446 2695921 completed\n",
      "447 2695922 completed\n",
      "448 2695923 completed\n",
      "449 2695924 completed\n",
      "450 2695925 completed\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "tks=0\n",
    "regex_error=[]\n",
    "re_shard=[]\n",
    "no_ref=[]\n",
    "indivs=[]\n",
    "abnormal=[]\n",
    "apps=[]\n",
    "lg=[]\n",
    "print(str(len(data.keys()))+\" to parse\")\n",
    "for i in data.keys():\n",
    "    res=None\n",
    "    count=count+1\n",
    "    if count<150:\n",
    "        continue\n",
    "    filename=base_path+'/'+i+'_chatgpt.json'\n",
    "    if os.path.exists(filename):\n",
    "        print(str(count)+' '+i+\" completed\")\n",
    "        continue\n",
    "    start=time.time()\n",
    "    \n",
    "    found=0\n",
    "    entry=Merged[Merged[\"ID\"]==i]\n",
    "    if type(data[i])==str:\n",
    "        print(\"pdf not available. download \"+i)\n",
    "        re_shard.append(i)\n",
    "        continue\n",
    "    try:\n",
    "        refs=data[i][\"references\"][0]\n",
    "        if \"found\" in refs.keys():\n",
    "            found=1\n",
    "    except:\n",
    "        print(str(i)+\" has no references, check it\")\n",
    "        print(entry[\"year\"].to_list()[0])\n",
    "        no_ref.append(i)\n",
    "        continue\n",
    "    if found==1:\n",
    "        #response=[]\n",
    "        #print(refs[\"found\"].keys())\n",
    "        #print(refs)\n",
    "        pages=list(refs[\"found\"].keys())\n",
    "        pages.sort()\n",
    "        text=\"\"\n",
    "        for j in pages:\n",
    "            text=text+refs[\"found\"][j][0]+\"\\n\"\n",
    "        position=None\n",
    "        position_a=None\n",
    "        try:\n",
    "            position=regex.search('(^|\\n)R(EFERENCES){e<=3}(\\n| )', text).span(0)[0]\n",
    "        except:\n",
    "            print(\"Regex error: \"+i)\n",
    "            regex_error.append(i)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            position_a=regex.search('(^|\\n)(APPENDIX){e<=3}(\\n| )', text).span(0)[0]\n",
    "            if position < position_a:\n",
    "                apps.append(i)\n",
    "                print(\"ref at \"+str(position)+ \". app at \"+ str(position_a) + \" of \"+str(len(text))+\" in \"+i)\n",
    "            else:\n",
    "                position_a=len(text)\n",
    "        except:\n",
    "            position_a=len(text)\n",
    "        start=time.time()\n",
    "        text=re.sub('\\nThis content downloaded(?s:.*?)jstor.org/terms\\n', \"\", text)\n",
    "        #prompt = 'given the following data. can you please format the references in the text into a .csv format with the following fields: authors, year, month, title, publisher, city, pages, the full reference. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data.\\n'+text[position:]\n",
    "        #prompt = 'given the following data. can you please format the references in the text into a .csv format with the following fields: authors, year, month, title, publisher, pages, the full reference. Please separate the author names with \"and\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data. Use ; as the delimiter.\\n'+text[position:]\n",
    "        #prompt = 'given the following data. can you please extract and format the references in the text into a json dictionary with the following fields: authors, year, month, title, publisher, city, pages, the full reference. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data.\\n'+text[position:]\n",
    "\n",
    "        #prompt = 'please extract the references in the following data and format it in chicago referencing style.'+text[position:position_a].upper()\n",
    "        #prompt = 'please extract the references in the following data and format it in harvard referencing style.'+text[position:position_a]\n",
    "        #prompt = 'Given the following reference list. Please extract the following fields: authors, year, month, title, publisher, pages, and the full reference in Chicago referencing style. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please \"NA\" as a placeholder for missing data.\\n'+text[position:position_a].upper()\n",
    "        prompt = 'Given the following reference list, please extract the following fields of the reference into a dictionary: authors, year, title, month, publisher, pages, and the full reference in Chicago referencing style. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please use \"NA\" as a placeholder for missing data.\\n'+text[position:position_a].upper()\n",
    "\n",
    "#         print(prompt)\n",
    "        toks=num_tokens_from_messages([{\"role\": \"user\", \"content\": prompt}])\n",
    "        tks=tks+toks\n",
    "        print(\"current time:-\", datetime.datetime.now())\n",
    "\n",
    "        indivs.append(toks)\n",
    "        \n",
    "        if toks>3501:\n",
    "            abnormal.append(i)\n",
    "            print(i+ \" this has an abnormally long reference list at \"+str(toks)+\", process separately\")\n",
    "            continue\n",
    "        try:\n",
    "            if toks<1100:\n",
    "                print(str(toks)+\" standard\")\n",
    "                res=get_completion(prompt, \"gpt-3.5-turbo\")\n",
    "                if res[\"choices\"][0][\"finish_reason\"]==\"length\":\n",
    "                    print(\"failed to return appropriate length\")\n",
    "                    res=get_completion(prompt, \"gpt-3.5-turbo-16k\")\n",
    "                response[i]=res\n",
    "            else:\n",
    "                print(str(toks)+\" too long. Using big context model.\")\n",
    "                lg.append(i)\n",
    "                res=get_completion(prompt, \"gpt-3.5-turbo-16k\")\n",
    "                response[i]=res\n",
    "\n",
    "            if res!=None:    \n",
    "                with open(filename, 'w') as f:\n",
    "                    json.dump({i:res}, f)\n",
    "                    print(str(count)+' '+i+\" completed\")\n",
    "        except:\n",
    "            print(\"this took too long to respond, complete next round. Moving on!\")\n",
    "\n",
    "    end=time.time()\n",
    "    print(end-start)\n",
    "    print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path+'/ECTA_2011_2020_chatgpt_output_max3500.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "0e64d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response.keys():\n",
    "    temp_dict={i:response[i]}\n",
    "    with open(base_path+'/'+i+'_chatgpt.json', 'w') as f:\n",
    "        json.dump(temp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "97bf7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"23357243\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce156de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response:\n",
    "    if response[i][\"choices\"][0][\"finish_reason\"]!=\"stop\":\n",
    "        print(i)\n",
    "#         print(response[i][\"choices\"][0]['message']['content'])\n",
    "#     else:\n",
    "#         print(\"**********\")\n",
    "#         print(response[i][\"choices\"][0]['message']['content'][0:200])\n",
    "#         print(\"**********\")\n",
    "#         print(response[i][\"choices\"][0]['message']['content'][-200:])\n",
    "#         print(\"**********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f1e09032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.111940298507463\n",
      "4.378571428571429\n",
      "3.5120481927710845\n",
      "3.7745664739884393\n"
     ]
    }
   ],
   "source": [
    "print(3097/134)\n",
    "print(613/140)\n",
    "print(1166/332)\n",
    "print(653/173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d877197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461.1111111111111"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "332*5000/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4ccbb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n",
      "2786\n",
      "1416\n"
     ]
    }
   ],
   "source": [
    "print(response[15][\"usage\"][\"completion_tokens\"])\n",
    "print(response[16][\"usage\"][\"completion_tokens\"])\n",
    "print(response[17][\"usage\"][\"completion_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "db3636ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537719298245614\n",
      "0.41852117731514715\n",
      "0.4611581920903955\n"
     ]
    }
   ],
   "source": [
    "print(613/response[15][\"usage\"][\"completion_tokens\"])\n",
    "print(1166/response[16][\"usage\"][\"completion_tokens\"])\n",
    "print(653/response[17][\"usage\"][\"completion_tokens\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib",
   "language": "python",
   "name": "lib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
