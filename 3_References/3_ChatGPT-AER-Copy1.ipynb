{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfbcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt         # displaying output images\n",
    "import cv2 \n",
    "import openai\n",
    "import json\n",
    "import regex\n",
    "import tiktoken\n",
    "import os\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "734146f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Refs Danae/Thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c4546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429a831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    #gpt-3.5-turbo-16k\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    r_out = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        request_timeout=1000\n",
    "    )\n",
    "    return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa75b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"/Users/sijiawu/Work/Refs Danae/Thesis/Data\"\n",
    "temp=base_path+'/PDFs/AER/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ffabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged=pd.read_excel(base_path+'/Combined/AER_M_sco_du.xlsx')\n",
    "Merged.loc[Merged['journal']=='The American Economic Review','journal']='AER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b354d404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AER'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged.journal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2d4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged[\"ID\"]=Merged[\"URL\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d310c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=\"/Users/sijiawu/Work/Refs Danae/Thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e959c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "aer_1=pt+\"/Data\\AER_refs_output_2011_2020_S.json\"\n",
    "aer_2=pt+\"/Data\\AER_refs_output_2011_2020_N.json\"\n",
    "aer_3=pt+\"/Data\\AER_refs_output_2008_2010_N.json\"\n",
    "aer_4=pt+\"/Data\\AER_refs_output_2001_2007_N.json\"\n",
    "aer_5=pt+\"/Data\\AER_refs_output_1991_2000_N.json\"\n",
    "aer_6=pt+\"/Data\\AER_refs_output_1991_2000_S.json\"\n",
    "aer_7=pt+\"/Data\\AER_refs_output_1981_1990_N.json\"\n",
    "aer_8=pt+\"/Data\\AER_refs_output_1981_1990_S.json\"\n",
    "aer_9=pt+\"/Data\\AER_refs_output_1971_1980.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec84aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}\n",
    "aer=[\n",
    "#     aer_1,\n",
    "    aer_2,\n",
    "#     aer_3,\n",
    "#     aer_4,\n",
    "#     aer_5,\n",
    "#     aer_6,\n",
    "#     aer_7,\n",
    "#     aer_8,\n",
    "#     aer_9\n",
    "     ]\n",
    "for file in aer:\n",
    "    with open(file) as f:\n",
    "        temp_data = json.load(f)\n",
    "        data=data|temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada755f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f568a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    #gpt-3.5-turbo-16k\n",
    "    #gpt-3.5-turbo-0613\n",
    "#   \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54918e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41348055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b836bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "459913dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlg\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lg' is not defined"
     ]
    }
   ],
   "source": [
    "len(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948d0688",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abnormal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mabnormal\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abnormal' is not defined"
     ]
    }
   ],
   "source": [
    "len(abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678643e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indivs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mindivs\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(lg)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3600\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indivs' is not defined"
     ]
    }
   ],
   "source": [
    "(len(indivs)*60+len(lg)*200)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028a7fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indivs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mindivs\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3600\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indivs' is not defined"
     ]
    }
   ],
   "source": [
    "len(indivs)*60/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21ce207",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indivs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mindivs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indivs' is not defined"
     ]
    }
   ],
   "source": [
    "len(indivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd9de53a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mapps\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apps' is not defined"
     ]
    }
   ],
   "source": [
    "len(apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ec0e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251 to parse\n",
      "1 26966478 completed\n",
      "2 26966479 completed\n",
      "3 26966480 completed\n",
      "4 26966481 completed\n",
      "2020\n",
      "current time:- 2023-11-08 01:58:53.082387\n",
      "26966482 this has an abnormally long reference list at 4954, process separately\n",
      "6 26966483 completed\n",
      "7 26966484 completed\n",
      "2020\n",
      "current time:- 2023-11-08 01:58:53.091617\n",
      "3090 too long. Using big context model.\n",
      "8 26966485 completed\n",
      "144.74091601371765\n",
      "3090\n",
      "9 26966486 completed\n",
      "10 26966487 completed\n",
      "11 26966518 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.851252\n",
      "26966519 this has an abnormally long reference list at 3653, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.862272\n",
      "26966520 this has an abnormally long reference list at 3723, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.870874\n",
      "26966521 this has an abnormally long reference list at 4079, process separately\n",
      "15 26966522 completed\n",
      "16 26966523 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.878296\n",
      "26966524 this has an abnormally long reference list at 4236, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.885112\n",
      "26966525 this has an abnormally long reference list at 4537, process separately\n",
      "19 26966526 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.892059\n",
      "26966527 this has an abnormally long reference list at 5264, process separately\n",
      "21 26966465 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:01:17.895979\n",
      "2798 too long. Using big context model.\n",
      "22 26966466 completed\n",
      "152.9186499118805\n",
      "2798\n",
      "2020\n",
      "current time:- 2023-11-08 02:03:50.833947\n",
      "2912 too long. Using big context model.\n",
      "23 26966467 completed\n",
      "156.55186891555786\n",
      "2912\n",
      "2020\n",
      "current time:- 2023-11-08 02:06:27.404046\n",
      "26966468 this has an abnormally long reference list at 3875, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:06:27.417651\n",
      "26966469 this has an abnormally long reference list at 4662, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:06:27.427602\n",
      "26966470 this has an abnormally long reference list at 5254, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:06:27.434185\n",
      "26966471 this has an abnormally long reference list at 3891, process separately\n",
      "28 26966472 completed\n",
      "29 26966473 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:06:27.438578\n",
      "2697 too long. Using big context model.\n",
      "30 26966474 completed\n",
      "133.56337785720825\n",
      "2697\n",
      "2020\n",
      "current time:- 2023-11-08 02:08:41.021163\n",
      "26966313 this has an abnormally long reference list at 3598, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:08:41.034265\n",
      "26966314 this has an abnormally long reference list at 3712, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:08:41.041604\n",
      "3007 too long. Using big context model.\n",
      "33 26966315 completed\n",
      "154.03046226501465\n",
      "3007\n",
      "34 26966316 completed\n",
      "35 26966317 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.089403\n",
      "26966318 this has an abnormally long reference list at 3988, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.104622\n",
      "26966319 this has an abnormally long reference list at 4757, process separately\n",
      "38 26966320 completed\n",
      "39 26966321 completed\n",
      "40 26966322 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.112767\n",
      "26966332 this has an abnormally long reference list at 3859, process separately\n",
      "42 26966333 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.119593\n",
      "26966334 this has an abnormally long reference list at 3660, process separately\n",
      "44 26966335 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.126362\n",
      "26966336 this has an abnormally long reference list at 4312, process separately\n",
      "46 26966337 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:11:15.130751\n",
      "2789 too long. Using big context model.\n",
      "47 26966338 completed\n",
      "144.73842597007751\n",
      "2789\n",
      "2020\n",
      "current time:- 2023-11-08 02:13:39.891427\n",
      "26966339 this has an abnormally long reference list at 3512, process separately\n",
      "49 26966340 completed\n",
      "50 26966341 completed\n",
      "51 26921625 completed\n",
      "52 26921626 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:13:39.903129\n",
      "26921627 this has an abnormally long reference list at 3894, process separately\n",
      "54 26921628 completed\n",
      "55 26921629 completed\n",
      "56 26921630 completed\n",
      "57 26921631 completed\n",
      "58 26921632 completed\n",
      "59 26921633 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:13:39.911137\n",
      "3045 too long. Using big context model.\n",
      "60 26921634 completed\n",
      "153.64418983459473\n",
      "3045\n",
      "2020\n",
      "current time:- 2023-11-08 02:16:13.575002\n",
      "26921635 this has an abnormally long reference list at 3920, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:16:13.585401\n",
      "26921610 this has an abnormally long reference list at 3933, process separately\n",
      "63 26921611 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:16:13.594422\n",
      "26921612 this has an abnormally long reference list at 4608, process separately\n",
      "65 26921613 completed\n",
      "66 26921614 completed\n",
      "67 26921615 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:16:13.601602\n",
      "26921616 this has an abnormally long reference list at 4452, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:16:13.606590\n",
      "3112 too long. Using big context model.\n",
      "69 26921617 completed\n",
      "170.2847318649292\n",
      "3112\n",
      "70 26921618 completed\n",
      "71 26921619 completed\n",
      "72 26921583 completed\n",
      "73 26921584 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:19:03.914223\n",
      "26921585 this has an abnormally long reference list at 4736, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:19:03.923610\n",
      "2858 too long. Using big context model.\n",
      "75 26921586 completed\n",
      "148.86559891700745\n",
      "2858\n",
      "2020\n",
      "current time:- 2023-11-08 02:21:32.809925\n",
      "26921587 this has an abnormally long reference list at 3922, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:21:32.819700\n",
      "26921588 this has an abnormally long reference list at 3578, process separately\n",
      "78 26921589 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:21:32.830711\n",
      "26921590 this has an abnormally long reference list at 5850, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:21:32.835464\n",
      "2696 too long. Using big context model.\n",
      "80 26921591 completed\n",
      "146.02179479599\n",
      "2696\n",
      "2020\n",
      "current time:- 2023-11-08 02:23:58.876608\n",
      "3472 too long. Using big context model.\n",
      "81 26921592 completed\n",
      "185.95129203796387\n",
      "3472\n",
      "2020\n",
      "current time:- 2023-11-08 02:27:04.849101\n",
      "26921596 this has an abnormally long reference list at 6652, process separately\n",
      "83 26921597 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:27:04.858096\n",
      "3421 too long. Using big context model.\n",
      "84 26921598 completed\n",
      "169.26662278175354\n",
      "3421\n",
      "2020\n",
      "current time:- 2023-11-08 02:29:54.145762\n",
      "26921599 this has an abnormally long reference list at 3853, process separately\n",
      "2020\n",
      "current time:- 2023-11-08 02:29:54.158511\n",
      "26921600 this has an abnormally long reference list at 4993, process separately\n",
      "87 26921601 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:29:54.165866\n",
      "26921602 this has an abnormally long reference list at 3604, process separately\n",
      "89 26921603 completed\n",
      "90 26921604 completed\n",
      "91 26921605 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:29:54.174512\n",
      "26897989 this has an abnormally long reference list at 5517, process separately\n",
      "93 26897990 completed\n",
      "94 26897991 completed\n",
      "95 26897992 completed\n",
      "96 26897993 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:29:54.179622\n",
      "3379 too long. Using big context model.\n",
      "97 26897994 completed\n",
      "172.83527994155884\n",
      "3379\n",
      "2020\n",
      "current time:- 2023-11-08 02:32:47.041970\n",
      "26897995 this has an abnormally long reference list at 6719, process separately\n",
      "99 26897996 completed\n",
      "100 26897997 completed\n",
      "101 26897998 completed\n",
      "102 26875123 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:32:47.053062\n",
      "26875124 this has an abnormally long reference list at 4483, process separately\n",
      "104 26875125 completed\n",
      "105 26875126 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:32:47.059571\n",
      "3219 too long. Using big context model.\n",
      "106 26875127 completed\n",
      "156.76785016059875\n",
      "3219\n",
      "107 26875128 completed\n",
      "108 26875129 completed\n",
      "109 26875130 completed\n",
      "110 26863273 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:35:23.849292\n",
      "3479 too long. Using big context model.\n",
      "111 26863274 completed\n",
      "181.4485182762146\n",
      "3479\n",
      "112 26863275 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:38:25.310815\n",
      "2843 too long. Using big context model.\n",
      "113 26863276 completed\n",
      "151.12148213386536\n",
      "2843\n",
      "2020\n",
      "current time:- 2023-11-08 02:40:56.447464\n",
      "2912 too long. Using big context model.\n",
      "114 26863277 completed\n",
      "163.6101360321045\n",
      "2912\n",
      "2020\n",
      "current time:- 2023-11-08 02:43:40.076292\n",
      "3105 too long. Using big context model.\n",
      "115 26863278 completed\n",
      "145.71292328834534\n",
      "3105\n",
      "116 26863279 completed\n",
      "117 26863280 completed\n",
      "2020\n",
      "current time:- 2023-11-08 02:46:05.802101\n",
      "3078 too long. Using big context model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 26863281 completed\n",
      "154.0221130847931\n",
      "3078\n",
      "2019\n",
      "current time:- 2023-11-08 02:48:39.844573\n",
      "26848478 this has an abnormally long reference list at 5383, process separately\n",
      "120 26848479 completed\n",
      "2019\n",
      "current time:- 2023-11-08 02:48:39.853376\n",
      "3012 too long. Using big context model.\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 08 Nov 2023 00:58:40 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '8229cfcb0e6e071c-CPT', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(toks)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m too long. Using big context model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m     lg\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m--> 103\u001b[0m     res\u001b[38;5;241m=\u001b[39m\u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-16k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     response[i]\u001b[38;5;241m=\u001b[39mres\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:    \n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#gpt-3.5-turbo-16k\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m----> 5\u001b[0m     r_out \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r_out\n",
      "File \u001b[0;32m~/Work/Refs Danae/lib/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Work/Refs Danae/lib/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Work/Refs Danae/lib/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Work/Refs Danae/lib/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Work/Refs Danae/lib/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 08 Nov 2023 00:58:40 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '8229cfcb0e6e071c-CPT', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "tks=0\n",
    "temp=0\n",
    "regex_error=[]\n",
    "re_shard=[]\n",
    "no_ref=[]\n",
    "indivs=[]\n",
    "abnormal=[]\n",
    "apps=[]\n",
    "lg=[]\n",
    "print(str(len(data.keys()))+\" to parse\")\n",
    "for i in data.keys():\n",
    "    res=None\n",
    "    count=count+1\n",
    "    \n",
    "\n",
    "    filename=base_path+'/'+i+'_chatgpt.json'\n",
    "    if os.path.exists(filename):\n",
    "        print(str(count)+' '+i+\" completed\")\n",
    "        continue\n",
    "    start=time.time()\n",
    "    \n",
    "    found=0\n",
    "    entry=Merged[Merged[\"ID\"]==i]\n",
    "    print(entry[\"year\"].to_list()[0])\n",
    "    if type(data[i])==str:\n",
    "        print(\"pdf not available. download \"+i)\n",
    "        re_shard.append(i)\n",
    "        continue\n",
    "    try:\n",
    "        refs=data[i][\"references\"][0]\n",
    "        if \"found\" in refs.keys():\n",
    "            found=1\n",
    "    except:\n",
    "        print(str(i)+\" has no references, check it\")\n",
    "        no_ref.append(i)\n",
    "        continue\n",
    "    if found==1:\n",
    "        #response=[]\n",
    "        #print(refs[\"found\"].keys())\n",
    "        #print(refs)\n",
    "        pages=list(refs[\"found\"].keys())\n",
    "        pages_int = [int(numeric_string) for numeric_string in pages]\n",
    "        pages_int.sort()\n",
    "        text=\"\"\n",
    "        for j in pages_int:\n",
    "            text=text+refs[\"found\"][str(j)][0]+\"\\n\"\n",
    "        \n",
    "#         print(text)\n",
    "        position=None\n",
    "        position_a=None\n",
    "        text=re.sub('\\nthis content downloaded(?s:.*?)terms and conditions\\n|\\nthis content downloaded(?s:.*?)jstor.org/terms\\n', \"\", text.lower(),re.M)\n",
    "        \n",
    "        try:\n",
    "            position=regex.search('(^|\\n)R(EFERENCES){e<=3}(\\n| )', text.upper()).span(0)[0]\n",
    "        except:\n",
    "            print(\"Regex error: \"+i)\n",
    "            regex_error.append(i)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            position_a=regex.search('(^|\\n)(APPENDIX){e<=3}(\\n| )', text.upper()).span(0)[0]\n",
    "            if position < position_a:\n",
    "                apps.append(i)\n",
    "                print(\"ref at \"+str(position)+ \". app at \"+ str(position_a) + \" of \"+str(len(text))+\" in \"+i)\n",
    "            else:\n",
    "                position_a=len(text)\n",
    "        except:\n",
    "            position_a=len(text)\n",
    "        start=time.time()\n",
    "        \n",
    "        #prompt = 'given the following data. can you please format the references in the text into a .csv format with the following fields: authors, year, month, title, publisher, city, pages, the full reference. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data.\\n'+text[position:]\n",
    "        #prompt = 'given the following data. can you please format the references in the text into a .csv format with the following fields: authors, year, month, title, publisher, pages, the full reference. Please separate the author names with \"and\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data. Use ; as the delimiter.\\n'+text[position:]\n",
    "        #prompt = 'given the following data. can you please extract and format the references in the text into a json dictionary with the following fields: authors, year, month, title, publisher, city, pages, the full reference. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please use quotes around text and \"\" for missing data.\\n'+text[position:]\n",
    "\n",
    "        #prompt = 'please extract the references in the following data and format it in chicago referencing style.'+text[position:position_a].upper()\n",
    "        #prompt = 'please extract the references in the following data and format it in harvard referencing style.'+text[position:position_a]\n",
    "        #prompt = 'Given the following reference list. Please extract the following fields: authors, year, month, title, publisher, pages, and the full reference in Chicago referencing style. Please separate the author names with \";\" as the delimiter if there are multiple authors. Please \"NA\" as a placeholder for missing data.\\n'+text[position:position_a].upper()\n",
    "        prompt = 'Given the following reference list, please extract the following fields of the reference into a dictionary: authors, year, title, month, publisher or journal, pages, and the full reference in Chicago referencing style. Please separate each author name with \";\" as the delimiter if there are multiple authors. Please use \"NA\" as a placeholder for missing data.\\n'+text[position:position_a].lower()\n",
    "#         print(prompt)\n",
    "        toks=num_tokens_from_messages([{\"role\": \"user\", \"content\": prompt}])\n",
    "        tks=tks+toks\n",
    "        \n",
    "        print(\"current time:-\", datetime.datetime.now())\n",
    "\n",
    "        \n",
    "        indivs.append(toks)\n",
    "        if toks>3501:\n",
    "            abnormal.append(i)\n",
    "            print(i+ \" this has an abnormally long reference list at \"+str(toks)+\", process separately\")\n",
    "            continue\n",
    "        temp=temp+1\n",
    "        if toks<1100:\n",
    "            print(str(toks)+\" standard\")\n",
    "            res=get_completion(prompt, \"gpt-3.5-turbo-1106\")\n",
    "            if res[\"choices\"][0][\"finish_reason\"]==\"length\":\n",
    "                print(\"failed to return appropriate length\")\n",
    "                res=get_completion(prompt, \"gpt-3.5-turbo-16k\")\n",
    "            response[i]=res\n",
    "        else:\n",
    "            print(str(toks)+\" too long. Using big context model.\")\n",
    "            lg.append(i)\n",
    "            res=get_completion(prompt, \"gpt-3.5-turbo-16k\")\n",
    "            response[i]=res\n",
    "            \n",
    "        if res!=None:    \n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump({i:res}, f)\n",
    "                print(str(count)+' '+i+\" completed\")\n",
    "                    \n",
    "    end=time.time()\n",
    "    print(end-start)\n",
    "    print(toks)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path+'/ECTA_2011_2020_chatgpt_output_max3500.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "0e64d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response.keys():\n",
    "    temp_dict={i:response[i]}\n",
    "    with open(base_path+'/'+i+'_chatgpt.json', 'w') as f:\n",
    "        json.dump(temp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "97bf7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"23357243\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce156de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in response:\n",
    "    if response[i][\"choices\"][0][\"finish_reason\"]!=\"stop\":\n",
    "        print(i)\n",
    "        print(response[i][\"choices\"][0]['message']['content'])\n",
    "    else:\n",
    "        print(\"**********\")\n",
    "        print(response[i][\"choices\"][0]['message']['content'][0:200])\n",
    "        print(\"**********\")\n",
    "        print(response[i][\"choices\"][0]['message']['content'][-200:])\n",
    "        print(\"**********\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f1e09032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.111940298507463\n",
      "4.378571428571429\n",
      "3.5120481927710845\n",
      "3.7745664739884393\n"
     ]
    }
   ],
   "source": [
    "print(3097/134)\n",
    "print(613/140)\n",
    "print(1166/332)\n",
    "print(653/173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d877197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461.1111111111111"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "332*5000/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4ccbb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n",
      "2786\n",
      "1416\n"
     ]
    }
   ],
   "source": [
    "print(response[15][\"usage\"][\"completion_tokens\"])\n",
    "print(response[16][\"usage\"][\"completion_tokens\"])\n",
    "print(response[17][\"usage\"][\"completion_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "db3636ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537719298245614\n",
      "0.41852117731514715\n",
      "0.4611581920903955\n"
     ]
    }
   ],
   "source": [
    "print(613/response[15][\"usage\"][\"completion_tokens\"])\n",
    "print(1166/response[16][\"usage\"][\"completion_tokens\"])\n",
    "print(653/response[17][\"usage\"][\"completion_tokens\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib",
   "language": "python",
   "name": "lib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
